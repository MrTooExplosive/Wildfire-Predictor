{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a646f2ca",
   "metadata": {},
   "source": [
    "# DeepAR Notes and Questions\n",
    "\n",
    "Do we need to hot encode city? Wouldn't latitude and longitude be better data in terms of percentages of fire within a given location?\n",
    "\n",
    "If cities were given a binary value, wouldn't the predictions be more suscetible to prediciting fires ONLY in the cities that had fires previously, and give a 0 percent prediction on cities that weren't in our training data?\n",
    "\n",
    "But I guess if the user is giving us a location, hot encoding the locations would be better.\n",
    "\n",
    "BUT.... web-services could take the location, web-scrape its latitude and longitude and have them pass those values to us to make a prediction.\n",
    "\n",
    "Just thinking out loud, maybe something we could consider."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1e879",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Importing Sagemaker and setting file parameters. DO NOT RUN THESE UNTIL WE ARE READY TO SEND THIS NOTEBOOK INTO AWS SAGEMAKER!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f557cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"sagemaker/Wildfire-DeepAR\"  # change to your desired S3 prefix\n",
    "region = sess.boto_region_name\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69507ea8",
   "metadata": {},
   "source": [
    "Import Necessary Files and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96816fb5",
   "metadata": {},
   "source": [
    "# Setting Up Data\n",
    "Download the cleaned CSV file here\n",
    "\n",
    "Refer to tutorial for assistance\n",
    "\n",
    "Mak will implmenet the preparation of the data by adding non\"true\" fire results to the cleaned csv.\n",
    "\n",
    "To accomplish this, we need to loop through every fire or weather station\n",
    "for each weather station, we loop throughout the range of dates... yes every single one, and add a 1 to \n",
    "the target attribute if there was a fire on that specific day, 0 if otherwise\n",
    "\n",
    "This will allow the DeepAR learning algorithm to gain a probability of a fire in a particular city.\n",
    "\n",
    "NOTE, this might prove challenging if the input for location is converted to latitude and longitude but im certain \n",
    "it's doable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad61584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the cleaned CSV file here\n",
    "# Refer to tutorial for assistance\n",
    "# Mak will implmenet the preparation of the data by adding non\"true\" fire results to the cleaned csv\n",
    "# To accomplish this, we need to loop through every fire or weather station\n",
    "# For each weather station, we loop throughout the range of dates... yes every single one, and add a 1 to \n",
    "# the target attribute if there was a fire on that specific day, 0 if otherwise\n",
    "# This will allow the DeepAR learning algorithm to gain a probability of a fire in a particular city.\n",
    "# NOTE, this might prove challenging if the input for location is converted to latitude and longitude but im certain \n",
    "# it's doable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ca7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data\n",
    "s3 = boto3.client(\"s3\")\n",
    "datafile = \"fireWithWeather.csv\"\n",
    "\n",
    "df = pd.read_csv(datafile)\n",
    "\n",
    "# Hopefully it's clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb76b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_path = \"{}/{}/output\".format(bucket, prefix)\n",
    "train_data_path = \"s3://{}/{}/train/train.json\".format(bucket, prefix)\n",
    "test_data_path = \"s3://{}/{}/test/test.json\".format(bucket, prefix)\n",
    "\n",
    "def series_to_obj(ts, cat=None):\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": list(ts)}\n",
    "    if cat:\n",
    "        obj[\"cat\"] = cat\n",
    "    return obj\n",
    "\n",
    "\n",
    "def series_to_jsonline(ts, cat=None):\n",
    "    return json.dumps(series_to_obj(ts, cat))\n",
    "\n",
    "with open(\"train.json\", \"w\") as fp:\n",
    "    for ts in violation_list_training:\n",
    "        fp.write(series_to_jsonline(ts))\n",
    "        fp.write(\"\\n\")\n",
    "! aws s3 mv train.json $train_data_path\n",
    "\n",
    "with open(\"test.json\", \"w\") as fp:\n",
    "    for ts in violation_list:\n",
    "        fp.write(series_to_jsonline(ts))\n",
    "        fp.write(\"\\n\")\n",
    "! aws s3 mv test.json $test_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cdd00b",
   "metadata": {},
   "source": [
    "# Training Algorithm \n",
    "\n",
    "Copied from the AWS GitHub training repo, modified for our needs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "from sagemaker import image_uris\n",
    "\n",
    "\n",
    "container = image_uris.retrieve(region=region, framework=\"forecasting-deepar\")\n",
    "\n",
    "deepar = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    use_spot_instances=True,  # use spot instances\n",
    "    max_run=1800,  # max training time in seconds\n",
    "    max_wait=1800,  # seconds to wait for spot instance\n",
    "    output_path=\"s3://{}/{}\".format(bucket, s3_output_path),\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "freq = \"D\"\n",
    "context_length = 30\n",
    "\n",
    "deepar.set_hyperparameters(\n",
    "    time_freq=freq, context_length=str(context_length), prediction_length=str(prediction_length)\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"mini_batch_size\": IntegerParameter(100, 400),\n",
    "    \"epochs\": IntegerParameter(200, 400),\n",
    "    \"num_cells\": IntegerParameter(30, 100),\n",
    "    \"likelihood\": CategoricalParameter([\"negative-binomial\", \"student-T\"]),\n",
    "    \"learning_rate\": ContinuousParameter(0.0001, 0.1),\n",
    "}\n",
    "\n",
    "objective_metric_name = \"test:RMSE\"\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    deepar,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=10,\n",
    "    strategy=\"Bayesian\",\n",
    "    objective_type=\"Minimize\",\n",
    "    max_parallel_jobs=10,\n",
    "    early_stopping_type=\"Auto\",\n",
    ")\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=\"s3://{}/{}/train/\".format(bucket, prefix), content_type=\"json\"\n",
    ")\n",
    "s3_input_test = sagemaker.inputs.TrainingInput(\n",
    "    s3_data=\"s3://{}/{}/test/\".format(bucket, prefix), content_type=\"json\"\n",
    ")\n",
    "\n",
    "tuner.fit({\"train\": s3_input_train}, include_cls_metadata=False)\n",
    "tuner.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
